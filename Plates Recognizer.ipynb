{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['imread', 'randint', 'sample', 'seed', 'uniform']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "\n",
    "#import imageio as im\n",
    "from scipy.misc import imread\n",
    "\n",
    "import random as rd\n",
    "from random import randint, uniform, sample, seed\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D \n",
    "from keras.models import Model, load_model\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Recognizer_v1(input_shape = (58, 58, 3), classes = 12):\n",
    "    \"\"\"\n",
    "    Keras CNN\n",
    "    INPUT -> CONV -> RELU -> MAXPOOL -> CONV -> RELU -> FC -> RELU -> OUTPUT\n",
    "    \"\"\"\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(16, (5, 5), strides = (1, 1), name = 'conv0')(X_input)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Maxpool\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # FLATTEN X (means convert it to a vector) + FC + RELU\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(256, name='fc0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # FULLYCONNECTED\n",
    "    X = Dense(classes, name='fc1')(X)\n",
    "    X = Activation('softmax')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='Recognizer')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Main program body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "\n",
    "img = imread(\"Plates_Train\\\\red_3.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\red_4.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\red_5.png\")\n",
    "tmp.append(img)\n",
    "\n",
    "img = imread(\"Plates_Train\\\\green_3.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\green_4.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\green_5.png\")\n",
    "tmp.append(img)\n",
    "\n",
    "img = imread(\"Plates_Train\\\\cyan_3.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\cyan_4.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\cyan_5.png\")\n",
    "tmp.append(img)\n",
    "\n",
    "img = imread(\"Plates_Train\\\\purple_3.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\purple_4.png\")\n",
    "tmp.append(img)\n",
    "img = imread(\"Plates_Train\\\\purple_5.png\")\n",
    "tmp.append(img)\n",
    "\n",
    "X_train = np.stack(tmp, axis=0)\n",
    "Y_train = np.eye(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES:\n",
    "# ========\n",
    "#\n",
    "# Red 3 = 0\n",
    "# Red 4 = 1\n",
    "# Red 5 = 2\n",
    "# \n",
    "# Green 3 = 3\n",
    "# Green 4 = 4\n",
    "# Green 5 = 5\n",
    "# \n",
    "# Cyan 3 = 6\n",
    "# Cyan 4 = 7\n",
    "# Cyan 5 = 8\n",
    "# \n",
    "# Purple 3 = 9\n",
    "# Purple 4 = 10\n",
    "# Purple 5 = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Готовим модель\n",
    "recon = Recognizer_v1(input_shape=(58, 58, 3), classes=12)\n",
    "recon.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recon.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 2.4640 - acc: 0.0833\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.9736 - acc: 0.6667\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.3127 - acc: 0.7500\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7605 - acc: 1.0000\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4255 - acc: 0.9167\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2585 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1513 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0864 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0713 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7481e-04 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.9875e-04 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.2069e-04 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.3118e-04 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.5273e-04 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7394e-04 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.5035e-04 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0793e-04 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.5218e-05 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.1258e-05 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.8883e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.5771e-05 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.4220e-05 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7194e-05 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.1953e-05 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.3357e-05 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.3344e-05 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.3540e-05 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.4929e-05 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7849e-05 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2314e-05 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.8573e-05 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.5200e-05 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3044e-05 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1494e-05 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0347e-05 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.5072e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.8862e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.4044e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.0269e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7040e-06 - acc: 1.0000\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "Test loss: 7.41590656617e-06\n",
      "Test accuracy: 1.0\n",
      "Wall time: 6.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recon.fit(X_train, Y_train, epochs=50, verbose=1)\n",
    "\n",
    "# Score trained model\n",
    "scores = recon.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Very Important!!!\n",
    "#\n",
    "recon.save(\"Recognizer_v1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
